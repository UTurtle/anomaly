{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일이 'audio_features.json' 경로에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_path, result_folder):\n",
    "    \"\"\"\n",
    "    Extract features and save plots to respective folders.\n",
    "    \"\"\"\n",
    "    # 결과 폴더 생성\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "    \n",
    "    # 파일 이름 추출\n",
    "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # 각 특징별 폴더 생성 및 이미지 경로 설정\n",
    "    def get_image_path(feature_name):\n",
    "        feature_folder = os.path.join(result_folder, feature_name)\n",
    "        os.makedirs(feature_folder, exist_ok=True)\n",
    "        return os.path.join(feature_folder, f\"{file_name}.png\")\n",
    "\n",
    "    # 예시 특징 데이터\n",
    "    return {\n",
    "        \"file_path\": file_path,\n",
    "        \"features\": {\n",
    "            \"zero_crossing_rate\": 0.012,\n",
    "            \"harmonic_to_noise_ratio\": 0.75,\n",
    "            \"spectral_flatness\": 0.3,\n",
    "            \"spectral_rolloff\": 2800.0,\n",
    "            \"rms_energy\": 0.05,\n",
    "            \"entropy\": 1.45,\n",
    "            \"waveform\": get_image_path(\"waveform\"),\n",
    "            \"envelope\": get_image_path(\"envelope\"),\n",
    "            \"cepstrum\": get_image_path(\"cepstrum\"),\n",
    "            \"mel_spectrogram_with_axes\": get_image_path(\"mel_spectrogram_with_axes\"),\n",
    "            \"mel_spectrogram_no_axes\": get_image_path(\"mel_spectrogram_no_axes\"),\n",
    "            \"mfcc\": get_image_path(\"mfcc\"),\n",
    "            \"linear_spectrogram_with_axes\": get_image_path(\"linear_spectrogram_with_axes\"),\n",
    "            \"linear_spectrogram_no_axes\": get_image_path(\"linear_spectrogram_no_axes\"),\n",
    "            \"chroma_features\": get_image_path(\"chroma_features\"),\n",
    "            \"spectral_centroid\": get_image_path(\"spectral_centroid\"),\n",
    "            \"spectral_bandwidth\": get_image_path(\"spectral_bandwidth\"),\n",
    "            \"power_spectrum\": get_image_path(\"power_spectrum\"),\n",
    "            \"std\": 0.123,\n",
    "            \"avg\": 0.456\n",
    "        },\n",
    "    }\n",
    "\n",
    "def create_json_structure(data_entries, output_json_path):\n",
    "    \"\"\"\n",
    "    Create a JSON file with structured data entries.\n",
    "    \"\"\"\n",
    "    data = {\"audio_features\": data_entries}\n",
    "    with open(output_json_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process all files and extract features.\n",
    "    \"\"\"\n",
    "    classes = [\"ToyCar\", \"ToyTrain\", \"bearing\", \"fan\", \"gearbox\", \"slider\", \"valve\"]\n",
    "    data_type = ['test', 'train']\n",
    "    all_entries = []\n",
    "\n",
    "    for class_name in classes:\n",
    "        for data in data_type:\n",
    "            folder_path = f'../unziped/dev/{class_name}/{data}'\n",
    "            result_folder = os.path.join(folder_path, \"Feature_Extraction_Results\")\n",
    "            os.makedirs(result_folder, exist_ok=True)\n",
    "            \n",
    "            # 모든 wav 파일 처리\n",
    "            wav_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "            \n",
    "            for wav_file in wav_files:\n",
    "                file_path = os.path.join(folder_path, wav_file)\n",
    "                features = extract_features(file_path, result_folder)\n",
    "                \n",
    "                # 섹션 정보 추출 (파일명에서 'section_' 뒤의 두 글자)\n",
    "                if 'section_' in wav_file:\n",
    "                    section_start = wav_file.find('section_') + len('section_')\n",
    "                    section = wav_file[section_start:section_start+2]\n",
    "                else:\n",
    "                    section = '00'  # 기본값\n",
    "\n",
    "                # note 추가 (자동 생성)\n",
    "                note = f\"This is a {class_name} machine, data type: {data}, file: {wav_file}\"\n",
    "                \n",
    "                entry = {\n",
    "                    \"file_path\": features[\"file_path\"],\n",
    "                    \"machine_type\": class_name,\n",
    "                    \"section\": section,\n",
    "                    \"domain\": data,  # 'train' 또는 'test'\n",
    "                    \"features\": features[\"features\"],\n",
    "                    \"note\": note  # 주석 추가\n",
    "                }\n",
    "                all_entries.append(entry)\n",
    "    \n",
    "    # JSON 파일로 저장\n",
    "    output_json_path = 'audio_features.json'\n",
    "    create_json_structure(all_entries, output_json_path)\n",
    "    print(f\"JSON 파일이 '{output_json_path}' 경로에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 작업 수: 8400\n",
      "사용 가능한 CPU 코어 수: 12, 사용되는 코어 수: 11\n",
      "............................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ToyCar:   4%|▍         | 52/1200 [10:21<3:48:35, 11.95s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:21<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:21<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:21<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "gearbox:   0%|          | 0/1200 [10:21<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:21<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:21<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:22<3:49:10, 11.98s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:22<3:49:13, 11.98s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:22<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:23<3:49:27, 11.99s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:23<3:49:32, 12.00s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:23<3:49:33, 12.00s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:23<3:49:33, 12.00s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:23<?, ?file/s]\n",
      "\n",
      "valve:   0%|          | 0/1200 [10:23<?, ?file/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ToyCar:   4%|▍         | 52/1200 [10:24<3:49:47, 12.01s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:24<3:49:54, 12.02s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:24<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:25<3:50:09, 12.03s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "ToyCar:   4%|▍         | 52/1200 [10:25<3:50:11, 12.03s/file]\n",
      "ToyTrain:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "bearing:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "fan:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "gearbox:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "slider:   0%|          | 0/1200 [10:25<?, ?file/s]\n",
      "valve:   0%|          | 0/1200 [10:25<?, ?file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 401\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJSON 파일이 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 경로에 저장되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 397\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mprint\u001b[39m()  \u001b[38;5;66;03m# 줄바꿈\u001b[39;00m\n\u001b[1;32m    396\u001b[0m output_json_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 397\u001b[0m \u001b[43mcreate_json_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_entries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJSON 파일이 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_json_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m 경로에 저장되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 308\u001b[0m, in \u001b[0;36mcreate_json_structure\u001b[0;34m(data_entries, output_json_path)\u001b[0m\n\u001b[1;32m    306\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_entries}\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_json_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m--> 308\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:325\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 325\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Matplotlib 백엔드를 'Agg'로 설정 (비대화형 백엔드)\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def extract_features(file_path, result_folder, min_freq=20, max_freq=8000, normalization='min-max'):\n",
    "    \"\"\"\n",
    "    Extract features from an audio file and save corresponding plots.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        result_folder (str): Directory to save feature plots.\n",
    "        min_freq (float): Minimum frequency for plotting.\n",
    "        max_freq (float): Maximum frequency for plotting.\n",
    "        normalization (str): Type of normalization for MFCC.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing file path and extracted features.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 오디오 로드\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "    except Exception as e:\n",
    "        print(f\"오디오 파일을 로드하는 중 오류 발생: {file_path}\\n오류 내용: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    # 특징 딕셔너리 초기화\n",
    "    features = {}\n",
    "\n",
    "    try:\n",
    "        # 1. Zero Crossing Rate\n",
    "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y=y))\n",
    "        features['zero_crossing_rate'] = zero_crossing_rate\n",
    "\n",
    "        # 2. Harmonic to Noise Ratio (HNR)\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "        hnr = np.mean(np.abs(y_harmonic)) / (np.mean(np.abs(y_percussive)) + 1e-10)\n",
    "        features['harmonic_to_noise_ratio'] = hnr\n",
    "\n",
    "        # 3. Spectral Flatness\n",
    "        spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=y))\n",
    "        features['spectral_flatness'] = spectral_flatness\n",
    "\n",
    "        # 4. Spectral Rolloff\n",
    "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "        features['spectral_rolloff'] = spectral_rolloff\n",
    "\n",
    "        # 5. RMS Energy\n",
    "        rms_energy = np.mean(librosa.feature.rms(y=y))\n",
    "        features['rms_energy'] = rms_energy\n",
    "\n",
    "        # 6. Entropy (Shannon Entropy)\n",
    "        histogram, bin_edges = np.histogram(y, bins=256, density=True)\n",
    "        entropy = -np.sum(histogram * np.log2(histogram + 1e-10))\n",
    "        features['entropy'] = entropy\n",
    "\n",
    "        # 7. Standard Deviation and Average\n",
    "        features['std'] = np.std(y)\n",
    "        features['avg'] = np.mean(y)\n",
    "\n",
    "        # 결과 폴더 생성\n",
    "        os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "        # 파일 이름 추출\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "        # 각 특징별로 폴더 생성 및 이미지 저장\n",
    "        def save_plot(fig, feature_name):\n",
    "            feature_folder = os.path.join(result_folder, feature_name)\n",
    "            os.makedirs(feature_folder, exist_ok=True)\n",
    "            return os.path.join(feature_folder, f\"{file_name}.png\")\n",
    "\n",
    "        # 8. Waveform Plot\n",
    "        fig, ax = compute_and_plot_waveform(y, sr)\n",
    "        waveform_path = save_plot(fig, 'waveform')\n",
    "        fig.savefig(waveform_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['waveform'] = waveform_path\n",
    "\n",
    "        # 9. Envelope Plot\n",
    "        fig, ax = compute_and_plot_envelope(y, sr)\n",
    "        envelope_path = save_plot(fig, 'envelope')\n",
    "        fig.savefig(envelope_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['envelope'] = envelope_path\n",
    "\n",
    "        # 10. Cepstrum Plot\n",
    "        fig, ax = compute_and_plot_cepstrum(y, sr, min_freq=min_freq, max_freq=max_freq)\n",
    "        cepstrum_path = save_plot(fig, 'cepstrum')\n",
    "        fig.savefig(cepstrum_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['cepstrum'] = cepstrum_path\n",
    "\n",
    "        # 11. Mel Spectrogram Plot\n",
    "        # (a) With axes\n",
    "        fig, ax = compute_and_plot_mel_spectrogram(y, sr, display_axes=True)\n",
    "        mel_spectrogram_with_axes_path = save_plot(fig, 'mel_spectrogram_with_axes')\n",
    "        fig.savefig(mel_spectrogram_with_axes_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['mel_spectrogram_with_axes'] = mel_spectrogram_with_axes_path\n",
    "\n",
    "        # (b) Without axes\n",
    "        fig, ax = compute_and_plot_mel_spectrogram(y, sr, display_axes=False)\n",
    "        mel_spectrogram_no_axes_path = save_plot(fig, 'mel_spectrogram_no_axes')\n",
    "        fig.savefig(mel_spectrogram_no_axes_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['mel_spectrogram_no_axes'] = mel_spectrogram_no_axes_path\n",
    "\n",
    "        # 12. MFCC Plot\n",
    "        fig, ax = compute_and_plot_mfcc(y, sr, normalization=normalization)\n",
    "        mfcc_path = save_plot(fig, 'mfcc')\n",
    "        fig.savefig(mfcc_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['mfcc'] = mfcc_path\n",
    "\n",
    "        # 13. Linear Spectrogram Plot\n",
    "        # (a) With axes\n",
    "        fig, ax = compute_and_plot_linear_spectrogram(y, sr, n_fft=256, hop_length=128, display_axes=True)\n",
    "        linear_spectrogram_with_axes_path = save_plot(fig, 'linear_spectrogram_with_axes')\n",
    "        fig.savefig(linear_spectrogram_with_axes_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['linear_spectrogram_with_axes'] = linear_spectrogram_with_axes_path\n",
    "\n",
    "        # (b) Without axes\n",
    "        fig, ax = compute_and_plot_linear_spectrogram(y, sr, n_fft=256, hop_length=128, display_axes=False)\n",
    "        linear_spectrogram_no_axes_path = save_plot(fig, 'linear_spectrogram_no_axes')\n",
    "        fig.savefig(linear_spectrogram_no_axes_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['linear_spectrogram_no_axes'] = linear_spectrogram_no_axes_path\n",
    "\n",
    "        # 14. Chroma Features Plot\n",
    "        fig, ax = compute_and_plot_chroma_features(y, sr)\n",
    "        chroma_features_path = save_plot(fig, 'chroma_features')\n",
    "        fig.savefig(chroma_features_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['chroma_features'] = chroma_features_path\n",
    "\n",
    "        # 15. Spectral Centroid Plot\n",
    "        fig, ax = compute_and_plot_spectral_centroid(y, sr)\n",
    "        spectral_centroid_path = save_plot(fig, 'spectral_centroid')\n",
    "        fig.savefig(spectral_centroid_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['spectral_centroid'] = spectral_centroid_path\n",
    "\n",
    "        # 16. Spectral Bandwidth Plot\n",
    "        fig, ax = compute_and_plot_spectral_bandwidth(y, sr)\n",
    "        spectral_bandwidth_path = save_plot(fig, 'spectral_bandwidth')\n",
    "        fig.savefig(spectral_bandwidth_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['spectral_bandwidth'] = spectral_bandwidth_path\n",
    "\n",
    "        # 17. Power Spectrum Plot\n",
    "        fig, ax = compute_and_plot_power_spectrum(y, sr)\n",
    "        power_spectrum_path = save_plot(fig, 'power_spectrum')\n",
    "        fig.savefig(power_spectrum_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        features['power_spectrum'] = power_spectrum_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"특징 추출 중 오류 발생: {file_path}\\n오류 내용: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"file_path\": file_path,\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "# 플롯 함수들\n",
    "def compute_and_plot_waveform(y: np.ndarray, sr: int):\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    librosa.display.waveshow(y, sr=sr, ax=ax)\n",
    "    ax.set_title('Waveform')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_envelope(y: np.ndarray, sr: int):\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    times = librosa.times_like(onset_env, sr=sr)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    ax.plot(times, onset_env)\n",
    "    ax.set_title('Envelope')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_cepstrum(y: np.ndarray, sr: int, min_freq: float, max_freq: float):\n",
    "    spectrum = np.fft.fft(y)\n",
    "    log_spectrum = np.log(np.abs(spectrum) + 1e-10)\n",
    "    cepstrum = np.fft.ifft(log_spectrum).real\n",
    "    quefrency = np.arange(len(cepstrum)) / sr\n",
    "    idx = (quefrency >= 1 / max_freq) & (quefrency <= 1 / min_freq)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    ax.plot(quefrency[idx], cepstrum[idx])\n",
    "    ax.set_title('Cepstrum')\n",
    "    ax.set_xlabel('Quefrency (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_mel_spectrogram(y: np.ndarray, sr: int, display_axes: bool):\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, fmin=20, fmax=8000)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    img = librosa.display.specshow(S_db, sr=sr, fmin=20, fmax=8000, ax=ax, cmap='viridis')\n",
    "    if not display_axes:\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.set_title('Mel Spectrogram')\n",
    "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    plt.tight_layout(pad=0)\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_linear_spectrogram(y: np.ndarray, sr: int, n_fft: int, hop_length: int, display_axes: bool):\n",
    "    S = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
    "    S_db = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    img = librosa.display.specshow(S_db, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear', ax=ax, cmap='magma')\n",
    "    if not display_axes:\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.set_title('Linear Spectrogram')\n",
    "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    plt.tight_layout(pad=0)\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_mfcc(y: np.ndarray, sr: int, normalization: str = \"min-max\"):\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    if normalization == \"min-max\":\n",
    "        mfccs_normalized = (mfccs - np.min(mfccs)) / (np.max(mfccs) - np.min(mfccs) + 1e-10)\n",
    "    elif normalization == \"z-score\":\n",
    "        mfccs_normalized = (mfccs - np.mean(mfccs)) / (np.std(mfccs) + 1e-10)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported normalization type. Use 'min-max' or 'z-score'.\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    img = librosa.display.specshow(mfccs_normalized, x_axis='time', ax=ax, cmap='coolwarm')\n",
    "    ax.set_title('MFCC')\n",
    "    fig.colorbar(img, ax=ax)\n",
    "    plt.tight_layout(pad=0)\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_chroma_features(y: np.ndarray, sr: int):\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    img = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', cmap='coolwarm', ax=ax)\n",
    "    ax.set_title('Chroma Features')\n",
    "    fig.colorbar(img, ax=ax)\n",
    "    plt.tight_layout(pad=0)\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_spectral_centroid(y: np.ndarray, sr: int):\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    times = librosa.times_like(spectral_centroids)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    ax.plot(times, spectral_centroids)\n",
    "    ax.set_title('Spectral Centroid')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_spectral_bandwidth(y: np.ndarray, sr: int):\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "    times = librosa.times_like(spectral_bandwidth)\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    ax.plot(times, spectral_bandwidth)\n",
    "    ax.set_title('Spectral Bandwidth')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Bandwidth (Hz)')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def compute_and_plot_power_spectrum(y: np.ndarray, sr: int):\n",
    "    S = np.abs(np.fft.fft(y))**2\n",
    "    freqs = np.fft.fftfreq(len(y), 1/sr)\n",
    "    idx = np.argsort(freqs)\n",
    "    idx = idx[freqs[idx] >= 0]\n",
    "    freqs = freqs[idx]\n",
    "    S = S[idx]\n",
    "    fig, ax = plt.subplots(figsize=(8, 2), dpi=100)  # 해상도 낮춤\n",
    "    ax.plot(freqs, S)\n",
    "    ax.set_title('Power Spectrum')\n",
    "    ax.set_xlabel('Frequency (Hz)')\n",
    "    ax.set_ylabel('Power')\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def create_json_structure(data_entries, output_json_path):\n",
    "    \"\"\"\n",
    "    Create a JSON file with structured data entries.\n",
    "\n",
    "    Parameters:\n",
    "        data_entries (list): List of feature dictionaries.\n",
    "        output_json_path (str): Path to save the JSON file.\n",
    "    \"\"\"\n",
    "    data = {\"audio_features\": data_entries}\n",
    "    with open(output_json_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def process_file(task):\n",
    "    \"\"\"\n",
    "    Wrapper function to process a single file.\n",
    "\n",
    "    Parameters:\n",
    "        task (tuple): Tuple containing all necessary arguments.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Processed feature dictionary or None if failed.\n",
    "    \"\"\"\n",
    "    class_name, data_type, file_path, result_folder, min_freq, max_freq, normalization = task\n",
    "    features = extract_features(file_path, result_folder, min_freq, max_freq, normalization)\n",
    "    if features is None:\n",
    "        return None\n",
    "\n",
    "    # 섹션 정보 추출 (파일명에서 'section_' 뒤의 두 글자)\n",
    "    wav_file = os.path.basename(file_path)\n",
    "    if 'section_' in wav_file:\n",
    "        section_start = wav_file.find('section_') + len('section_')\n",
    "        section = wav_file[section_start:section_start+2]\n",
    "    else:\n",
    "        section = '00'  # 기본값\n",
    "\n",
    "    # note 추가 (자동 생성)\n",
    "    note = f\"This is a {class_name} machine, data type: {data_type}, file: {wav_file}\"\n",
    "\n",
    "    entry = {\n",
    "        \"file_path\": features[\"file_path\"],\n",
    "        \"machine_type\": class_name,\n",
    "        \"section\": section,\n",
    "        \"domain\": data_type,  # 'train' 또는 'test'\n",
    "        \"features\": features[\"features\"],\n",
    "        \"note\": note  # 주석 추가\n",
    "    }\n",
    "    return entry\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process all files and extract features with progress tracking.\n",
    "    \"\"\"\n",
    "    # 클래스 목록 및 데이터 타입 설정\n",
    "    classes = [\"ToyCar\", \"ToyTrain\", \"bearing\", \"fan\", \"gearbox\", \"slider\", \"valve\"]\n",
    "    data_types = ['test', 'train']\n",
    "    all_entries = []\n",
    "\n",
    "    # 데이터 디렉토리 설정\n",
    "    base_dir = '../unziped/dev'\n",
    "\n",
    "    # 모든 파일 목록 수집\n",
    "    tasks = []\n",
    "    for class_name in classes:\n",
    "        for data_type in data_types:\n",
    "            folder_path = os.path.join(base_dir, class_name, data_type)\n",
    "            result_folder = os.path.join(folder_path, \"Feature_Extraction_Results\")\n",
    "            os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"폴더를 찾을 수 없습니다: {folder_path}\", file=sys.stderr)\n",
    "                continue\n",
    "\n",
    "            # 모든 wav 파일 처리\n",
    "            wav_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "            for wav_file in wav_files:\n",
    "                file_path = os.path.join(folder_path, wav_file)\n",
    "                tasks.append((class_name, data_type, file_path, result_folder, 20, 8000, 'min-max'))\n",
    "\n",
    "    # 디버깅: 총 작업 수 출력\n",
    "    print(f\"총 작업 수: {len(tasks)}\")\n",
    "    if len(tasks) == 0:\n",
    "        print(\"처리할 파일이 없습니다. 데이터 경로와 파일 존재 여부를 확인해주세요.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # 멀티프로세싱 풀 생성 (CPU 코어 수에 맞춤)\n",
    "    num_workers = max(1, cpu_count() - 1)  # 시스템 안정성을 위해 하나의 코어는 남겨둠\n",
    "    print(f\"사용 가능한 CPU 코어 수: {cpu_count()}, 사용되는 코어 수: {num_workers}\")\n",
    "\n",
    "    # 멀티프로세싱과 단순 진행 표시 (점 출력) 사용하여 병렬 처리 및 진행 상황 표시\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        for result in pool.imap_unordered(process_file, tasks):\n",
    "            if result is not None:\n",
    "                all_entries.append(result)\n",
    "                # 점 출력 ('.') 후 플러시하여 즉시 표시\n",
    "                print('.', end='', flush=True)\n",
    "\n",
    "    # 줄바꿈 후 JSON 파일 저장 완료 메시지 출력\n",
    "    print()  # 줄바꿈\n",
    "    output_json_path = 'audio_features.json'\n",
    "    create_json_structure(all_entries, output_json_path)\n",
    "    print(f\"JSON 파일이 '{output_json_path}' 경로에 저장되었습니다.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현재 위의 코드를 실행하면 png파일만 출력됨.\n",
    "\n",
    "- 중간에 json에 경로나 특성을 저장하면서 오류가 발생함.\n",
    "- png는 이미 다 생성됬으므로 json 경로와 실수 특성만 다시 생성하면 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def extract_features(file_path, result_folder, min_freq=20, max_freq=8000, normalization='min-max'):\n",
    "    \"\"\"\n",
    "    Extract numeric features from an audio file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        result_folder (str): Directory where existing feature plots are stored.\n",
    "        min_freq (float): Minimum frequency for cepstrum plotting (unused).\n",
    "        max_freq (float): Maximum frequency for cepstrum plotting (unused).\n",
    "        normalization (str): Type of normalization for MFCC (unused).\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing file path, numeric features, and plot paths.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 오디오 로드\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "    except Exception as e:\n",
    "        print(f\"오디오 파일을 로드하는 중 오류 발생: {file_path}\\n오류 내용: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    # 특징 딕셔너리 초기화\n",
    "    features = {}\n",
    "\n",
    "    try:\n",
    "        # 1. Zero Crossing Rate\n",
    "        zero_crossing_rate = float(np.mean(librosa.feature.zero_crossing_rate(y=y)))\n",
    "        features['zero_crossing_rate'] = zero_crossing_rate\n",
    "\n",
    "        # 2. Harmonic to Noise Ratio (HNR)\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "        hnr = float(np.mean(np.abs(y_harmonic)) / (np.mean(np.abs(y_percussive)) + 1e-10))\n",
    "        features['harmonic_to_noise_ratio'] = hnr\n",
    "\n",
    "        # 3. Spectral Flatness\n",
    "        spectral_flatness = float(np.mean(librosa.feature.spectral_flatness(y=y)))\n",
    "        features['spectral_flatness'] = spectral_flatness\n",
    "\n",
    "        # 4. Spectral Rolloff\n",
    "        spectral_rolloff = float(np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)))\n",
    "        features['spectral_rolloff'] = spectral_rolloff\n",
    "\n",
    "        # 5. RMS Energy\n",
    "        rms_energy = float(np.mean(librosa.feature.rms(y=y)))\n",
    "        features['rms_energy'] = rms_energy\n",
    "\n",
    "        # 6. Entropy (Shannon Entropy)\n",
    "        histogram, bin_edges = np.histogram(y, bins=256, density=True)\n",
    "        entropy = float(-np.sum(histogram * np.log2(histogram + 1e-10)))\n",
    "        features['entropy'] = entropy\n",
    "\n",
    "        # 7. Standard Deviation and Average\n",
    "        features['std'] = float(np.std(y))\n",
    "        features['avg'] = float(np.mean(y))\n",
    "\n",
    "        # 이미지 경로 추가 (이미지가 이미 생성되어 있다고 가정)\n",
    "        # Feature_Extraction_Results 폴더 내의 각 특징별 폴더에 이미지가 저장되어 있다고 가정\n",
    "        plot_features = [\n",
    "            'waveform',\n",
    "            'envelope',\n",
    "            'cepstrum',\n",
    "            'mel_spectrogram_with_axes',\n",
    "            'mel_spectrogram_no_axes',\n",
    "            'mfcc',\n",
    "            'linear_spectrogram_with_axes',\n",
    "            'linear_spectrogram_no_axes',\n",
    "            'chroma_features',\n",
    "            'spectral_centroid',\n",
    "            'spectral_bandwidth',\n",
    "            'power_spectrum'\n",
    "        ]\n",
    "\n",
    "        for feature_name in plot_features:\n",
    "            plot_folder = os.path.join(result_folder, feature_name)\n",
    "            plot_path = os.path.join(plot_folder, f\"{os.path.splitext(os.path.basename(file_path))[0]}.png\")\n",
    "            if os.path.exists(plot_path):\n",
    "                features[feature_name] = plot_path\n",
    "            else:\n",
    "                features[feature_name] = None  # 또는 다른 적절한 값\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"특징 추출 중 오류 발생: {file_path}\\n오류 내용: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"file_path\": file_path,\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "def create_json_structure(data_entries, output_json_path):\n",
    "    \"\"\"\n",
    "    Create a JSON file with structured data entries.\n",
    "\n",
    "    Parameters:\n",
    "        data_entries (list): List of feature dictionaries.\n",
    "        output_json_path (str): Path to save the JSON file.\n",
    "    \"\"\"\n",
    "    data = {\"audio_features\": data_entries}\n",
    "    with open(output_json_path, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def process_file(task):\n",
    "    \"\"\"\n",
    "    Wrapper function to process a single file.\n",
    "\n",
    "    Parameters:\n",
    "        task (tuple): Tuple containing all necessary arguments.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Processed feature dictionary or None if failed.\n",
    "    \"\"\"\n",
    "    class_name, data_type, file_path, result_folder, min_freq, max_freq, normalization = task\n",
    "    features = extract_features(file_path, result_folder, min_freq, max_freq, normalization)\n",
    "    if features is None:\n",
    "        return None\n",
    "\n",
    "    # 섹션 정보 추출 (파일명에서 'section_' 뒤의 두 글자)\n",
    "    wav_file = os.path.basename(file_path)\n",
    "    if 'section_' in wav_file:\n",
    "        section_start = wav_file.find('section_') + len('section_')\n",
    "        section = wav_file[section_start:section_start+2]\n",
    "    else:\n",
    "        section = '00'  # 기본값\n",
    "\n",
    "    # note 추가 (자동 생성)\n",
    "    note = f\"This is a {class_name} machine, data type: {data_type}, file: {wav_file}\"\n",
    "\n",
    "    entry = {\n",
    "        \"file_path\": features[\"file_path\"],\n",
    "        \"machine_type\": class_name,\n",
    "        \"section\": section,\n",
    "        \"domain\": data_type,  # 'train' 또는 'test'\n",
    "        \"features\": features[\"features\"],\n",
    "        \"note\": note  # 주석 추가\n",
    "    }\n",
    "    return entry\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process all files and extract features with progress tracking.\n",
    "    \"\"\"\n",
    "    # 클래스 목록 및 데이터 타입 설정\n",
    "    classes = [\"ToyCar\", \"ToyTrain\", \"bearing\", \"fan\", \"gearbox\", \"slider\", \"valve\"]\n",
    "    data_types = ['test', 'train']\n",
    "    all_entries = []\n",
    "\n",
    "    # 데이터 디렉토리 설정\n",
    "    base_dir = '../unziped/dev'\n",
    "\n",
    "    # 모든 파일 목록 수집\n",
    "    tasks = []\n",
    "    for class_name in classes:\n",
    "        for data_type in data_types:\n",
    "            folder_path = os.path.join(base_dir, class_name, data_type)\n",
    "            result_folder = os.path.join(folder_path, \"Feature_Extraction_Results\")\n",
    "            os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "            if not os.path.exists(folder_path):\n",
    "                print(f\"폴더를 찾을 수 없습니다: {folder_path}\", file=sys.stderr)\n",
    "                continue\n",
    "\n",
    "            # 모든 wav 파일 처리\n",
    "            wav_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
    "            for wav_file in wav_files:\n",
    "                file_path = os.path.join(folder_path, wav_file)\n",
    "                tasks.append((class_name, data_type, file_path, result_folder, 20, 8000, 'min-max'))\n",
    "\n",
    "    # 디버깅: 총 작업 수 출력\n",
    "    print(f\"총 작업 수: {len(tasks)}\")\n",
    "    if len(tasks) == 0:\n",
    "        print(\"처리할 파일이 없습니다. 데이터 경로와 파일 존재 여부를 확인해주세요.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # 멀티프로세싱 풀 생성 (CPU 코어 수에 맞춤)\n",
    "    num_workers = max(1, cpu_count() - 1)  # 시스템 안정성을 위해 하나의 코어는 남겨둠\n",
    "    print(f\"사용 가능한 CPU 코어 수: {cpu_count()}, 사용되는 코어 수: {num_workers}\")\n",
    "\n",
    "    # 멀티프로세싱과 단순 진행 표시 (점 출력) 사용하여 병렬 처리 및 진행 상황 표시\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        for result in pool.imap_unordered(process_file, tasks):\n",
    "            if result is not None:\n",
    "                all_entries.append(result)\n",
    "                # 점 출력 ('.') 후 플러시하여 즉시 표시\n",
    "                print('.', end='', flush=True)\n",
    "\n",
    "    # 줄바꿈 후 JSON 파일 저장 완료 메시지 출력\n",
    "    print()  # 줄바꿈\n",
    "    output_json_path = 'audio_features.json'\n",
    "    try:\n",
    "        create_json_structure(all_entries, output_json_path)\n",
    "        print(f\"JSON 파일이 '{output_json_path}' 경로에 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"JSON 파일 저장 중 오류 발생: {e}\", file=sys.stderr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
