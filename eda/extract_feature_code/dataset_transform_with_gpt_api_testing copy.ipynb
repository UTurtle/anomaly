{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 데이터 하나가 잘 inference 되는지 확인하고 진행 (api는 신중히 접근)\n",
    "\n",
    "### data reforming to using gpt\n",
    "- api키는 무조건 자기 환경변수로 저장해두거나 지울것.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      7\u001b[0m completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ]\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/openai_gpt/lib/python3.11/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set your OpenAI API key\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_text\u001b[39m(text):\n",
      "File \u001b[0;32m~/anaconda3/envs/openai_gpt/lib/python3.11/site-packages/openai/_client.py:105\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    103\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Set your OpenAI API key\n",
    "\n",
    "def translate_text(text):\n",
    "    if not text.strip():\n",
    "        print(\"text의 내용이 비어있기 때문에 skip 됬습니다.\")\n",
    "        return \"\"  # Return empty string if note is empty\n",
    "    \n",
    "    prompt = f\"Translate the following Korean text to English and look like expert:\\n\\n{text}\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        translated_text = completion.choices[0].message\n",
    "        return translated_text\n",
    "    except:\n",
    "        print(\"실패했습니다.\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "text = \"\"\n",
    "output = translate_text(text)\n",
    "print(output)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "text = \"고주파수에서 앞뒤 1초의 강도가 매우 약함.\\n저중주파수(2kHz, 3kHz)에서 0.5kHz 폭만큼 강도가 약해지는 구간 관측됨.\\n스파이크 패턴이 비주기적으로 저주파수에서 고주파수까지 존재하나 높은 주파수일수록 강도가 점점 작아짐.\\n고중주파수(6kHz-7kHz)에서 1kHz 폭만큼 강도가 약해지는 구간 관측됨.\"\n",
    "output = translate_text(text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 밑의 코드는 실행하면 바로 api를 사용해서 data transform이 진행됨!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    if not text.strip():\n",
    "        print(\"text의 내용이 비어있기 때문에 skip 됬습니다.\")\n",
    "        return \"\"  # Return empty string if note is empty\n",
    "    \n",
    "    prompt = f\"Translate the following Korean text to English and look like expert:\\n\\n{text}\"\n",
    "    \n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        translated_text = completion.choices[0].message\n",
    "        return translated_text\n",
    "    except:\n",
    "        print(\"실패했습니다.\")\n",
    "        return \"\"\n",
    "\n",
    "def translate_notes_in_json(input_file, output_file, max_entries=None):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        data = json.load(infile)\n",
    "    \n",
    "    audio_features = data.get(\"audio_features\", [])\n",
    "    \n",
    "    # Filter out entries with empty 'note' fields\n",
    "    non_empty_features = [feature for feature in audio_features if feature.get('note', '').strip()] # 빈 노트는 건너뜀\n",
    "    \n",
    "    translated_data = []\n",
    "\n",
    "    for idx, feature in enumerate(non_empty_features):\n",
    "        if max_entries and idx >= max_entries:\n",
    "            break\n",
    "        \n",
    "        note = feature.get('note', '').strip()\n",
    "        translated_note = translate_text(note)\n",
    "        feature['note'] = translated_note  # Update the note with the translated text\n",
    "        translated_data.append(feature)\n",
    "        print(f\"Translated note for file {feature.get('file_path', '')}\")\n",
    "    \n",
    "    # Save the translated data into the output_file\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump({\"audio_features\": translated_data}, outfile, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Translated data has been saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json = \"audio_features_note.json\"  # Input file with Korean notes\n",
    "    output_json = \"audio_features_note_transform.json\"  # Output file with translated notes\n",
    "    # Set max_entries to limit the number of entries processed during testing\n",
    "    translate_notes_in_json(input_json, output_json, max_entries=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4o Mini 토큰 비용 계산\n",
    "\n",
    "#### **주어진 조건**\n",
    "- **입력:** 200자 미만의 한국어 → 약 `100~120 토큰`\n",
    "- **출력:** 400자 정도 되는 영어 → 약 `200~250 토큰`\n",
    "- **데이터 개수:** 400개\n",
    "- **GPT-4o Mini 토큰 비용:**\n",
    "  - **입력 토큰:** 1백만 개당 **$0.15**\n",
    "  - **출력 토큰:** 1백만 개당 **$0.60**\n",
    "\n",
    "---\n",
    "\n",
    "### **계산 과정**\n",
    "\n",
    "1. **평균 입력/출력 토큰 계산**\n",
    "   - **평균 입력 토큰:** \\( \\frac{100 + 120}{2} = 110 \\)  \n",
    "   - **평균 출력 토큰:** \\( \\frac{200 + 250}{2} = 225 \\)  \n",
    "   - **평균 총 토큰 (입력 + 출력):** \\( 110 + 225 = 335 \\)\n",
    "\n",
    "2. **총 토큰 수**\n",
    "   - \\( 335 \\, \\text{토큰/데이터} \\times 400 \\, \\text{데이터} = 134,000 \\, \\text{토큰} \\)\n",
    "\n",
    "3. **비용 계산**\n",
    "   - **입력 토큰 비용:**  \n",
    "     \\( 134,000 \\, \\text{토큰 중 입력 토큰} \\)은 대략 \\( 110 \\, \\text{토큰} \\)이므로,  \n",
    "     \\( 110 \\times 400 = 44,000 \\, \\text{입력 토큰} \\)  \n",
    "     - 1백만 개당 $0.15:\n",
    "     \\[\n",
    "     \\frac{44,000}{1,000,000} \\times 0.15 = 0.0066 \\, \\text{USD}\n",
    "     \\]\n",
    "   \n",
    "   - **출력 토큰 비용:**  \n",
    "     \\( 134,000 \\, \\text{토큰 중 출력 토큰} \\)은 대략 \\( 225 \\, \\text{토큰} \\)이므로,  \n",
    "     \\( 225 \\times 400 = 90,000 \\, \\text{출력 토큰} \\)  \n",
    "     - 1백만 개당 $0.60:\n",
    "     \\[\n",
    "     \\frac{90,000}{1,000,000} \\times 0.60 = 0.054 \\, \\text{USD}\n",
    "     \\]\n",
    "\n",
    "4. **총 비용**\n",
    "   - **입력 비용 + 출력 비용**:\n",
    "     \\[\n",
    "     0.0066 + 0.054 = 0.0606 \\, \\text{USD}\n",
    "     \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **결과**\n",
    "- **총 토큰 수:** 134,000 토큰\n",
    "- **예상 비용:** 약 **$0.0606** (모델 요금이 $0.15/1M 입력 토큰, $0.60/1M 출력 토큰일 경우)\n",
    "\n",
    "---\n",
    "\n",
    "**참고**: 실제 비용은 사용량, 토큰 크기, 요금 정책에 따라 달라질 수 있습니다. OpenAI의 [최신 요금 정책](https://openai.com/api/pricing/?utm_source=chatgpt.com)을 확인하여 정확한 비용을 확인하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# -----------------------------\n",
    "# 설정 파라미터\n",
    "# -----------------------------\n",
    "\n",
    "# 원본 JSON 파일 경로\n",
    "AUDIO_FEATURES_JSON = \"../../extract_feature_code/audio_features.json\"\n",
    "\n",
    "# 노트 정보가 담긴 JSON 파일 경로\n",
    "AUDIO_FEATURES_NOTE_JSON = \"../../extract_feature_code/audio_features_note_transform.json\"\n",
    "\n",
    "# 백업을 위한 원본 파일 복사 경로\n",
    "BACKUP_JSON = \"../../extract_feature_code/audio_features_backup.json\"\n",
    "\n",
    "# -----------------------------\n",
    "# 함수 정의\n",
    "# -----------------------------\n",
    "\n",
    "def backup_file(original_file, backup_file):\n",
    "    \"\"\"\n",
    "    원본 파일을 백업합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shutil.copyfile(original_file, backup_file)\n",
    "        print(f\"백업 성공: {backup_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"백업 실패: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    JSON 파일을 로드합니다.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"JSON 파일을 찾을 수 없습니다: {file_path}\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def update_notes(original_data, notes_data):\n",
    "    \"\"\"\n",
    "    original_data의 각 항목에 notes_data의 note를 업데이트합니다.\n",
    "    단, notes_data의 note가 빈 문자열(\"\")인 경우 업데이트하지 않습니다.\n",
    "    \"\"\"\n",
    "    # file_path를 키로 하는 딕셔너리 생성 (빠른 검색을 위해)\n",
    "    notes_dict = { \n",
    "        os.path.normpath(entry['file_path']): entry['note'] \n",
    "        for entry in notes_data.get(\"audio_features\", [])\n",
    "    }\n",
    "    \n",
    "    updated_count = 0\n",
    "    skipped_count = 0\n",
    "    not_found = []\n",
    "    \n",
    "    for feature in original_data.get(\"audio_features\", []):\n",
    "        # 파일 경로 정규화 (운영체제에 따라 경로 구분자가 다를 수 있음)\n",
    "        feature_path = os.path.normpath(feature.get(\"file_path\", \"\"))\n",
    "        \n",
    "        if feature_path in notes_dict:\n",
    "            new_note = notes_dict[feature_path]\n",
    "            if new_note.strip():  # 새로운 노트가 빈 문자열이 아닌 경우에만 업데이트\n",
    "                feature['note'] = new_note  # 노트 업데이트\n",
    "                updated_count += 1\n",
    "                # print(f\"업데이트됨: {feature_path}\")\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "                # print(f\"건너뜀 (빈 노트): {feature_path}\")\n",
    "        else:\n",
    "            not_found.append(feature_path)\n",
    "    \n",
    "    return updated_count, skipped_count, not_found\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    \"\"\"\n",
    "    데이터를 JSON 파일로 저장합니다.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"업데이트된 JSON 파일이 저장되었습니다: {file_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 메인 실행 흐름\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # 1. 원본 파일 백업\n",
    "    backup_file(AUDIO_FEATURES_JSON, BACKUP_JSON)\n",
    "    \n",
    "    # 2. JSON 파일 로드\n",
    "    original_data = load_json(AUDIO_FEATURES_JSON)\n",
    "    notes_data = load_json(AUDIO_FEATURES_NOTE_JSON)\n",
    "    \n",
    "    # 3. 노트 업데이트\n",
    "    updated_count, skipped_count, not_found = update_notes(original_data, notes_data)\n",
    "    \n",
    "    # 4. 업데이트된 데이터 저장\n",
    "    save_json(original_data, AUDIO_FEATURES_JSON)\n",
    "    \n",
    "    # 5. 결과 요약\n",
    "    print(f\"총 {updated_count}개의 항목이 업데이트되었습니다.\")\n",
    "    print(f\"총 {skipped_count}개의 항목이 빈 노트로 인해 건너뛰어졌습니다.\")\n",
    "    if not_found:\n",
    "        print(f\"노트를 찾을 수 없는 파일 경로 ({len(not_found)}개):\")\n",
    "        for path in not_found:\n",
    "            print(f\" - {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
